{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "pytorch_logistic_regression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO9csi1PVHYv",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression with PyTorch\n",
        "## 1. About Logistic Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "BEZeDdHXVHYz",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Logistic Regression Basics\n",
        "\n",
        "#### Classification algorithm\n",
        "- Example: Spam vs No Spam\n",
        "    - Input: Bunch of words\n",
        "    - Output: Probability spam or not\n",
        "\n",
        "#### Basic Comparison\n",
        "- **Linear regression**\n",
        "    - Output: numeric value given inputs\n",
        "- **Logistic regression**:\n",
        "    - Output: probability [0, 1] given input belonging to a class\n",
        "    \n",
        "    \n",
        "#### Input/Output Comparison\n",
        "- **Linear regression: Multiplication**\n",
        "    - Input: [1]\n",
        "        - Output: 2\n",
        "    - Input: [2]\n",
        "        - Output: 4\n",
        "    - Trying to model the relationship `y = 2x`\n",
        "- **Logistic regression: Spam**\n",
        "    - Input: \"Sign up to get 1 million dollars by tonight\"\n",
        "        - Output: p = 0.8\n",
        "    - Input: \"This is a receipt for your recent purchase with Amazon\"\n",
        "        - Output: p = 0.3\n",
        "    - **p: probability it is spam**\n",
        "        \n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERw3HQGPVHY0",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Problems of Linear Regression\n",
        "- Example\n",
        "    - Fever\n",
        "    - **Input**: temperature\n",
        "    - **Output**: fever or no fever\n",
        "- Remember\n",
        "    - **Linear regression**: minimize error between points and line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZjXXTO6VHY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "775ddd49-18d5-423a-b4cf-a4d6e09afcae"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "x = [1, 5, 10, 10, 25, 50, 70, 75, 100]\n",
        "y = [0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
        "\n",
        "colors = np.random.rand(len(x))\n",
        "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
        "plt.ylabel(\"Fever\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "\n",
        "plt.scatter(x, y, c=colors, alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx3k7b50VHY9",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression Problem 1**\n",
        "<br> Fever value can go negative (below 0) and positive (above 1).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmUQFEu1VHY-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "d88d97c3-113c-4ca8-bd88-ff59427743b8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [1, 5, 10, 10, 25, 50, 70, 75, 300]\n",
        "y = [0, 0, 0, 0, 0, 1, 1, 1, 1]\n",
        "\n",
        "colors = np.random.rand(len(x))\n",
        "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
        "plt.ylabel(\"Fever\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "\n",
        "plt.scatter(x, y, c=colors, alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JmDkYtJVHZD",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression Problem 2**\n",
        "<br> Fever points not predicted with outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsPuLFxMVHZE",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Logistic Regression In-Depth\n",
        "\n",
        "#### Predicting Probability\n",
        "- Linear regression doesn't work\n",
        "- Instead of predicting direct values: **predict probability**\n",
        "\n",
        "<img src=\"https://github.com/ritchieng/deep-learning-wizard/blob/master/docs/deep_learning/practical_pytorch/images/cross_entropy_final_4.png?raw=1\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
        "\n",
        "#### Logistic Function $g()$ \n",
        "- Two-class logistic regression\n",
        "- $ y = A x + b$\n",
        "- $ g(y) = A x + b $\n",
        "- $g(y) = \\frac {1} {1 + e^{-y}} = \\frac {1} {1 + e^{-(A x + b)}}$\n",
        "- $g(y)$ = Estimated probability that $y = 1$ given $x$\n",
        "\n",
        "\n",
        "#### Softmax Function $g()$ \n",
        "- Multi-class logistic regression\n",
        "- Generalization of logistic function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxQWJw8KVHZG",
        "colab_type": "text"
      },
      "source": [
        "#### Cross Entropy Function $D()$\n",
        "- $D(S, L) = L log S - (1-L)log(1-S)$\n",
        "    - If L = 0 (label)\n",
        "        - $D(S, 0) = - log(1-S)$\n",
        "            - $- log(1-S)$: less positive if $S \\longrightarrow 0 $\n",
        "            - $- log(1-S)$: more positive if $S \\longrightarrow 1 $ (BIGGER LOSS)\n",
        "    - If L = 1 (label)\n",
        "        - $D(S, 1) = log S$\n",
        "            - $logS$: less negative if $S \\longrightarrow 1 $\n",
        "            - $logS$: more negative if $S \\longrightarrow 0 $ (BIGGER LOSS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH-Qo8MZVHZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c3f77df0-74fc-4497-b8be-28626f08c91e"
      },
      "source": [
        "import math\n",
        "print(-math.log(1 - 0.00001))\n",
        "print(-math.log(1 - 0.99999))\n",
        "\n",
        "print(math.log(0.99999))\n",
        "print(math.log(0.00001))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0000050000287824e-05\n",
            "11.51292546497478\n",
            "-1.0000050000287824e-05\n",
            "-11.512925464970229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXSsoKt8VHZS",
        "colab_type": "text"
      },
      "source": [
        "#### Cross Entropy Loss $L$\n",
        "- Goal: Minimizing Cross Entropy Loss\n",
        "- $ L = \\frac {1}{N} \\sum_i D(g(Ax_i + b), L_i)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiX2TKygVHZT",
        "colab_type": "text"
      },
      "source": [
        "## 2. Building a Logistic Regression Model with PyTorch\n",
        "\n",
        "<img src=\"https://github.com/ritchieng/deep-learning-wizard/blob/master/docs/deep_learning/practical_pytorch/images/lr2.png?raw=1\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>\n",
        "\n",
        "### Steps\n",
        "- Step 1: Load Dataset\n",
        "- Step 2: Make Dataset Iterable\n",
        "- Step 3: Create Model Class\n",
        "- Step 4: Instantiate Model Class\n",
        "- Step 5: Instantiate Loss Class\n",
        "- Step 6: Instantiate Optimizer Class\n",
        "- Step 7: Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPBAFPeTVHZV",
        "colab_type": "text"
      },
      "source": [
        "### Step 1a: Loading MNIST Train Dataset\n",
        "**Images from 1 to 9**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCBcfZ-QVHZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0iLZ5TOVHZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = dsets.MNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBaeUs_sVHZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdde52fd-ac6b-45c5-a62d-697b6ec1cfd7"
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zm23JPHVHZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "647c6b66-e117-457b-c68d-63e366baa9a1"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
              "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
              "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
              "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
              "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
              "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
              "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
              "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
              "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
              "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
              "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
              "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
              "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
              "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
              "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
              "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]), 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tenm_nOOVHZq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc03090c-9939-4155-93a5-e1a990291ae8"
      },
      "source": [
        "type(train_dataset[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7fSZPJxVHZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6735289e-3ac8-4a0b-e797-3f4d2aeff8e2"
      },
      "source": [
        "# Input Matrix\n",
        "train_dataset[0][0].size()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMo8rYqnVHZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95bab0e1-2216-42cd-8367-9bc968111093"
      },
      "source": [
        "# Label\n",
        "train_dataset[0][1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9MXmwMDVHZ3",
        "colab_type": "text"
      },
      "source": [
        "#### Displaying MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE2Ff6jqVHZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfqVlA0YVHZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dffb48d-db9a-431d-e52f-57f8777671b6"
      },
      "source": [
        "train_dataset[0][0].numpy().shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVRbKT7dVHaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_img = train_dataset[0][0].numpy().reshape(28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzeozNM_VHaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f35e63cd-8116-438e-f385-4b770c8cae4c"
      },
      "source": [
        "plt.imshow(show_img, cmap='gray')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff4849e5320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HqVnvyoVHaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6b1b4b8-e7d9-4761-8d18-5ec3cbefac61"
      },
      "source": [
        "# Label\n",
        "train_dataset[0][1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLjFdss9VHaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_img = train_dataset[1][0].numpy().reshape(28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3Kx2At_VHaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d04b376a-3294-4141-beb7-a1832d5e3d4a"
      },
      "source": [
        "plt.imshow(show_img, cmap='gray')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff4cc7a02b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liawzVYWVHaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8cdc0c27-bc29-4e19-ac13-1eabfbf4e127"
      },
      "source": [
        "# Label\n",
        "train_dataset[1][1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyux9ufuVHai",
        "colab_type": "text"
      },
      "source": [
        "### Step 1b: Loading MNIST Test Dataset\n",
        "- Show our algorithm works beyond the data we have trained on.\n",
        "- Out-of-sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vrZBessVHal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZsWxPa1VHap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bac63e9-6f73-4526-a9f3-789bab834344"
      },
      "source": [
        "len(test_dataset)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlO007XjVHas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf8b90f3-05d4-4f4d-945f-5b093f754460"
      },
      "source": [
        "type(test_dataset[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BvPcgupVHaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "852b0364-e0e7-465c-f6de-dafdeffb7dae"
      },
      "source": [
        "# Image matrix\n",
        "test_dataset[0][0].size()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK53R48uVHa0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a4aa2415-5e1d-48ae-c6e5-44fa97ad545a"
      },
      "source": [
        "show_img = test_dataset[0][0].numpy().reshape(28, 28)\n",
        "plt.imshow(show_img, cmap='gray')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff4cc852ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCcIOJEHYgSQIO5DEvwEvYRv57rmVLgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSWSOkYGVHa4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fc2cae9-5e80-4789-ca38-1533d78c2c41"
      },
      "source": [
        "# Label\n",
        "test_dataset[0][1]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_jW5er2VHa7",
        "colab_type": "text"
      },
      "source": [
        "### Step 2: Make Dataset Iterable\n",
        "- Aim: make the dataset iterable\n",
        "- **totaldata**: 60000\n",
        "- **minibatch**: 100\n",
        "    - Number of examples in 1 iteration\n",
        "- **iterations**: 3000\n",
        "    - 1 iteration: one mini-batch forward & backward pass\n",
        "- **epochs**\n",
        "    - 1 epoch: running through the whole dataset once\n",
        "    - $epochs = iterations \\div \\frac{totaldata}{minibatch} = 3000 \\div \\frac{60000}{100} = 5 $\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2rC3yccVHa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0696771e-b71f-4628-b8dd-b9d3859f0959"
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msfr1F0hVHa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rqTeRs4VHbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_iters = 3000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3txsZ2lVHbJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "026f8ead-efbc-4855-eade-763a7a8ea665"
      },
      "source": [
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "num_epochs"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIQundvZVHbQ",
        "colab_type": "text"
      },
      "source": [
        "#### Create Iterable Object: Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf9RztohVHbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw6_Q2G_VHbY",
        "colab_type": "text"
      },
      "source": [
        "#### Check Iterability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRTmMdOiVHbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cae27b15-461a-4506-e6f8-c2d6e791ac0e"
      },
      "source": [
        "import collections\n",
        "isinstance(train_loader, collections.Iterable)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ8iv8iBVHbf",
        "colab_type": "text"
      },
      "source": [
        "#### Create Iterable Object: Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM4Iq-MYVHbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterable object\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmK6mxWBVHbk",
        "colab_type": "text"
      },
      "source": [
        "#### Check Iterability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE8zIMMUVHbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba1483e3-8b62-4a7c-abfe-449297e30310"
      },
      "source": [
        "isinstance(test_loader, collections.Iterable)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-8sEFmaVHb1",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbUZl4muVHb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same as linear regression! \n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vKBAnmIVHb4",
        "colab_type": "text"
      },
      "source": [
        "### Step 4: Instantiate Model Class\n",
        "- Input dimension: \n",
        "    - Size of image\n",
        "    - $28 \\times 28 = 784$\n",
        "- Output dimension: 10\n",
        "    - 0, 1, 2, 3, 4, 5, 6, 7, 8, 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-AxYc14VHb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7225477a-1f30-4772-ae39-7d67b28aa468"
      },
      "source": [
        "# Size of images\n",
        "train_dataset[0][0].size()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIpC46UbVHb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = 28*28\n",
        "output_dim = 10\n",
        "\n",
        "model = LogisticRegressionModel(input_dim, output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k75WbeHgVHb_",
        "colab_type": "text"
      },
      "source": [
        "### Step 5: Instantiate Loss Class\n",
        "- **Logistic Regression**: Cross Entropy Loss\n",
        "    - _Linear Regression: MSE_\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHWIcJymVHcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKkQSrWdVHcH",
        "colab_type": "text"
      },
      "source": [
        "#### What happens in `nn.CrossEntropyLoss()`?\n",
        "- Computes softmax (logistic/softmax function)\n",
        "- Computes cross entropy\n",
        "\n",
        "<img src=\"https://github.com/ritchieng/deep-learning-wizard/blob/master/docs/deep_learning/practical_pytorch/images/cross_entropy_final_4.png?raw=1\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYKVPPDQVHcL",
        "colab_type": "text"
      },
      "source": [
        "### Step 6: Instantiate Optimizer Class\n",
        "- Simplified equation\n",
        "    - $\\theta = \\theta - \\eta \\cdot \\nabla_\\theta $\n",
        "        - $\\theta$: parameters (our variables)\n",
        "        - $\\eta$: learning rate (how fast we want to learn)\n",
        "        - $\\nabla_\\theta$: parameters' gradients\n",
        "- Even simplier equation\n",
        "    - `parameters = parameters - learning_rate * parameters_gradients`\n",
        "    - **At every iteration, we update our model's parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXC9OlagVHcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlvmqqHRVHcR",
        "colab_type": "text"
      },
      "source": [
        "### Parameters In-Depth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bxJQ8QgFVHcS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e924e65a-d666-4cf8-909d-09d81a8e096d"
      },
      "source": [
        "print(model.parameters())\n",
        "\n",
        "print(len(list(model.parameters())))\n",
        "\n",
        "# FC 1 Parameters \n",
        "print(list(model.parameters())[0].size())\n",
        "\n",
        "# FC 1 Bias Parameters\n",
        "print(list(model.parameters())[1].size())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<generator object Module.parameters at 0x7ff4cc7f5eb8>\n",
            "2\n",
            "torch.Size([10, 784])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qtzX5huVHcZ",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/ritchieng/deep-learning-wizard/blob/master/docs/deep_learning/practical_pytorch/images/lr_params2.png?raw=1\" alt=\"deeplearningwizard\" style=\"width: 900px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vedXzI63VHcb",
        "colab_type": "text"
      },
      "source": [
        "### Step 7: Train Model\n",
        "- Process \n",
        "    1. Convert inputs/labels to variables\n",
        "    2. Clear gradient buffets\n",
        "    3. Get output given inputs \n",
        "    4. Get loss\n",
        "    5. Get gradients w.r.t. parameters\n",
        "    6. Update parameters using gradients\n",
        "        - `parameters = parameters - learning_rate * parameters_gradients`\n",
        "    7. REPEAT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6SCPUcPVHcc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f247784a-d4c2-4eb8-fdcd-f3ab53a5e59e"
      },
      "source": [
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images as Variable\n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "        labels = labels\n",
        "        \n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "        \n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        iter += 1\n",
        "        \n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Load images to a Torch Variable\n",
        "                images = images.view(-1, 28*28).requires_grad_()\n",
        "                \n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "                \n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "                \n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "            \n",
        "            accuracy = 100 * correct / total\n",
        "            \n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 1.828819751739502. Accuracy: 66\n",
            "Iteration: 1000. Loss: 1.6164941787719727. Accuracy: 75\n",
            "Iteration: 1500. Loss: 1.3092541694641113. Accuracy: 78\n",
            "Iteration: 2000. Loss: 1.235580563545227. Accuracy: 80\n",
            "Iteration: 2500. Loss: 0.9882506728172302. Accuracy: 81\n",
            "Iteration: 3000. Loss: 1.0075889825820923. Accuracy: 82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaWXR0tkVHch",
        "colab_type": "text"
      },
      "source": [
        "#### Break Down Accuracy Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hw7SVOrVHci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e794bfb5-f9fb-460d-b8c2-05720ba89638"
      },
      "source": [
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "    iter_test += 1\n",
        "    images = images.view(-1, 28*28).requires_grad_()\n",
        "    outputs = model(images)\n",
        "    if iter_test == 1:\n",
        "        print('OUTPUTS')\n",
        "        print(outputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OUTPUTS\n",
            "tensor([[-5.3113e-01, -1.0376e+00, -4.6718e-01, -2.3832e-01,  3.9108e-02,\n",
            "         -4.3469e-01, -1.1110e+00,  3.0440e+00, -2.2426e-01,  8.3483e-01],\n",
            "        [ 4.1897e-02, -1.1547e-01,  1.2949e+00,  7.7148e-01, -1.9290e+00,\n",
            "          7.5300e-01,  9.5148e-01, -1.9187e+00,  2.1591e-01, -1.7475e+00],\n",
            "        [-9.0393e-01,  2.3381e+00,  1.5896e-01,  5.3337e-02, -6.1447e-01,\n",
            "         -3.3328e-01, -1.8178e-01, -1.2244e-01,  1.4468e-01, -4.6219e-01],\n",
            "        [ 2.8540e+00, -2.4054e+00, -2.6355e-01, -2.8588e-01, -9.9867e-01,\n",
            "          6.7822e-01,  9.9116e-01,  1.8958e-02, -6.0885e-01, -4.5325e-01],\n",
            "        [-7.9245e-02, -2.0860e+00,  3.7290e-01, -8.2314e-01,  1.7590e+00,\n",
            "         -4.1508e-01,  8.9320e-02,  4.0421e-01, -2.5733e-02,  7.9248e-01],\n",
            "        [-1.3684e+00,  2.8495e+00,  4.1509e-02,  1.3729e-01, -7.3053e-01,\n",
            "         -4.8295e-01, -7.0727e-01, -8.0229e-02,  3.9847e-01, -2.8356e-01],\n",
            "        [-1.2957e+00, -1.3127e+00, -7.5100e-01,  2.4548e-01,  1.3076e+00,\n",
            "          2.0604e-01, -6.8731e-01,  7.4534e-01,  4.3630e-01,  8.2052e-01],\n",
            "        [-1.1461e+00, -5.6629e-01, -4.2658e-01, -1.7540e-01,  8.3475e-01,\n",
            "          1.5495e-01,  7.7607e-02, -2.0263e-03, -1.2703e-01,  1.3261e+00],\n",
            "        [ 4.2949e-01, -3.9197e-01,  7.2994e-01, -1.3127e+00,  5.1676e-01,\n",
            "         -1.9679e-01,  4.8209e-01, -1.0798e+00, -1.3637e-01,  3.2254e-01],\n",
            "        [-7.5060e-01, -9.2630e-01, -1.3368e+00, -1.5177e+00,  1.1872e+00,\n",
            "         -3.1108e-01, -4.7040e-01,  1.7031e+00,  1.4198e-01,  1.6541e+00],\n",
            "        [ 3.1099e+00, -1.8002e+00,  3.5428e-01,  1.0650e+00, -6.6557e-01,\n",
            "          1.0280e+00, -5.1717e-01, -1.5448e+00,  5.9923e-01, -1.7993e+00],\n",
            "        [ 8.3283e-01, -6.3855e-01,  2.0096e-01, -2.1457e-01,  3.7877e-01,\n",
            "         -3.9525e-01,  7.3562e-01, -1.1614e+00,  1.9816e-01, -6.5100e-01],\n",
            "        [-9.5803e-01, -1.6289e+00, -8.5088e-01, -9.8120e-01,  1.2832e+00,\n",
            "         -1.5274e-01, -4.3097e-01,  1.1659e+00,  9.2926e-02,  2.1178e+00],\n",
            "        [ 2.8775e+00, -2.4248e+00, -4.1118e-01, -1.1368e-01, -4.3384e-01,\n",
            "          8.3455e-01, -3.7815e-01, -7.3446e-01,  5.4768e-01,  4.1546e-02],\n",
            "        [-1.2175e+00,  2.6106e+00, -1.9731e-01,  2.2539e-01, -1.0598e+00,\n",
            "         -2.3870e-01, -1.8308e-01, -2.4861e-01,  2.6064e-01, -3.5487e-01],\n",
            "        [ 5.2587e-01, -8.3350e-01, -7.5776e-02,  1.2623e+00, -5.6274e-01,\n",
            "          8.3538e-01, -1.6289e-01, -3.7244e-01,  4.6515e-01, -7.5468e-01],\n",
            "        [-3.8959e-01, -2.0722e+00, -4.0591e-02, -8.1327e-01,  1.3109e+00,\n",
            "         -6.4085e-01, -4.7625e-01,  8.4996e-01,  9.0607e-02,  1.5478e+00],\n",
            "        [ 9.5273e-02, -1.4225e+00, -5.9409e-01,  4.0885e-01, -2.7496e-01,\n",
            "         -2.4564e-01, -8.5176e-01,  2.7093e+00, -5.6430e-01,  5.2207e-01],\n",
            "        [-9.6307e-01, -5.7400e-01,  1.1329e-01,  8.1297e-01, -6.3083e-01,\n",
            "          2.1045e-01,  9.0353e-01, -4.6064e-01,  1.4319e-01, -4.8972e-01],\n",
            "        [-8.6823e-01, -1.4492e+00, -5.2573e-01, -2.8611e-01,  1.8872e+00,\n",
            "          2.2318e-02, -1.9214e-01,  9.0857e-02, -1.7176e-01,  1.3788e+00],\n",
            "        [-9.9484e-01, -4.0257e-01, -1.5253e+00, -1.1856e-01,  3.4172e-01,\n",
            "          2.0399e-01, -1.2713e+00,  1.7312e+00,  3.0233e-01,  1.3958e+00],\n",
            "        [-6.1215e-01, -1.8000e+00,  1.7926e-02,  2.4370e-01,  4.0231e-01,\n",
            "          6.1348e-01,  2.3184e+00, -1.4343e+00,  2.0827e-01,  1.7458e-01],\n",
            "        [ 3.1138e-03, -5.2870e-02,  2.1113e-01, -7.3994e-01,  9.8045e-01,\n",
            "         -1.1172e+00,  1.0314e+00, -8.2173e-02, -3.1404e-01,  1.0404e-02],\n",
            "        [-1.8580e-02, -9.6865e-01, -6.0917e-01,  3.4283e-01, -1.0135e-02,\n",
            "          1.0240e+00,  8.0495e-02, -1.0126e+00,  7.3365e-01,  5.8378e-02],\n",
            "        [-6.0157e-01, -1.0675e+00, -1.5977e-02, -2.5242e-01,  1.4252e+00,\n",
            "         -2.7267e-01, -1.7281e-01,  2.5799e-01, -2.6942e-01,  1.0065e+00],\n",
            "        [ 4.2050e+00, -2.7413e+00,  3.4827e-01, -1.0179e+00, -2.6162e-01,\n",
            "          1.0223e+00,  8.5936e-01, -1.3717e+00, -2.5911e-01, -1.3512e+00],\n",
            "        [-3.6489e-01, -1.2640e+00, -4.1553e-01, -1.2265e-01,  3.9449e-02,\n",
            "         -1.4064e-01, -6.9224e-01,  1.8637e+00, -3.4876e-01,  1.1035e+00],\n",
            "        [-2.7511e-01, -2.4125e+00, -1.0617e-01, -7.7633e-01,  2.2298e+00,\n",
            "          2.0454e-02, -3.5664e-02,  1.7023e-01,  8.4212e-02,  1.3962e+00],\n",
            "        [ 2.4416e+00, -2.3762e+00, -1.9566e-02,  1.0201e+00, -1.3068e+00,\n",
            "          8.4409e-01, -2.0256e-01, -8.5198e-01,  5.1290e-01, -7.6654e-01],\n",
            "        [-1.0181e+00,  1.2986e+00, -2.3786e-01,  2.0196e-01, -4.1078e-01,\n",
            "          1.3502e-01,  8.4105e-02, -1.2857e-01,  2.4688e-01, -4.2710e-01],\n",
            "        [-8.2235e-01, -1.6973e-01, -1.0495e+00,  2.0869e+00, -1.1952e+00,\n",
            "          7.4510e-01, -5.2332e-01,  4.2237e-01,  1.5847e-01, -1.0546e-01],\n",
            "        [-8.1763e-01,  1.1376e+00, -2.5744e-01,  2.6108e-01, -4.4142e-01,\n",
            "          1.0474e-02, -1.5629e-01,  1.8702e-02,  1.8218e-01,  1.4058e-02],\n",
            "        [-1.2111e+00, -7.7544e-01, -8.1707e-01,  2.4363e+00, -6.0611e-01,\n",
            "          1.2702e+00, -4.5367e-01, -1.0822e+00,  3.6203e-01, -2.9990e-01],\n",
            "        [ 1.7748e+00, -1.8871e+00,  7.3044e-01, -1.4410e+00,  7.5449e-01,\n",
            "          3.3176e-01,  1.3525e+00, -1.0944e+00, -3.1524e-01, -1.5726e-01],\n",
            "        [-9.0790e-01, -2.6080e-01,  7.4991e-01, -5.0420e-01, -2.2087e-01,\n",
            "         -5.3833e-01, -1.5351e+00,  1.6369e+00,  6.4881e-01,  2.9541e-01],\n",
            "        [ 4.3033e-01, -1.3108e+00,  2.5658e+00,  4.0274e-01, -8.4231e-01,\n",
            "          7.3122e-02,  4.7951e-01, -4.3744e-01,  4.0961e-01, -1.9935e+00],\n",
            "        [-6.0209e-01, -1.4659e+00,  1.4979e-01,  9.2321e-03, -1.0046e-01,\n",
            "         -5.4006e-01, -6.3510e-01,  2.1690e+00, -4.0981e-01,  1.0399e+00],\n",
            "        [-1.2195e+00,  2.0313e+00, -4.0184e-01,  7.4741e-02, -6.1280e-01,\n",
            "         -1.0250e-01, -1.3009e-01,  1.0239e-01,  3.9260e-01, -1.1168e-01],\n",
            "        [ 3.2143e-01,  3.8154e-01,  6.3670e-01,  1.2217e+00, -1.8455e+00,\n",
            "          3.5356e-01,  3.1762e-01, -1.2379e+00,  6.2020e-01, -1.2222e+00],\n",
            "        [-1.4532e+00,  2.8713e+00, -4.0190e-01,  2.7929e-01, -1.2509e+00,\n",
            "         -1.4740e-01, -2.5801e-01, -5.0572e-01,  5.7065e-01, -2.9030e-01],\n",
            "        [-5.8686e-01,  1.4856e+00, -4.3014e-02,  6.9470e-02, -5.1042e-01,\n",
            "         -2.1448e-01, -1.0069e-01, -6.8856e-02,  1.0261e-01, -1.9689e-01],\n",
            "        [-7.9035e-01, -7.1748e-01, -1.5084e-01, -5.6449e-01,  6.6336e-02,\n",
            "         -2.5174e-01, -6.6110e-01,  1.8816e+00, -3.2396e-01,  1.2505e+00],\n",
            "        [-1.9080e+00, -4.5311e-01, -3.4705e-01, -4.9931e-01,  2.1121e+00,\n",
            "         -6.8492e-01, -7.7893e-01,  7.5128e-01,  2.5211e-01,  1.6094e+00],\n",
            "        [-5.1666e-01,  9.3521e-01,  9.6801e-01,  3.3850e-02, -2.9622e-01,\n",
            "         -3.1107e-01,  2.3977e-01, -1.1458e+00,  3.1859e-01, -6.0891e-01],\n",
            "        [-1.1407e+00,  1.1057e-01, -4.1328e-02,  1.0667e+00, -6.0069e-01,\n",
            "          3.3916e-01,  2.8993e-01, -1.7928e-01, -3.6422e-02, -5.3410e-01],\n",
            "        [ 1.2950e-01, -1.3436e+00, -4.7520e-01,  1.6813e+00, -6.2773e-01,\n",
            "          1.0342e+00, -9.3391e-02, -1.4020e+00,  1.0516e+00, -3.4605e-01],\n",
            "        [-1.4271e+00,  3.1348e-01,  7.3504e-02,  6.5359e-01, -8.8226e-02,\n",
            "          2.3989e-01, -9.5899e-02, -1.0381e-01,  2.7980e-01, -7.9455e-02],\n",
            "        [-7.3944e-01, -4.6149e-01,  1.2131e+00, -5.4157e-01,  4.2430e-01,\n",
            "         -6.5324e-01,  6.3104e-01, -5.1980e-01,  7.6141e-02,  8.8819e-02],\n",
            "        [-1.0960e+00, -2.8008e+00, -1.2819e+00, -1.2949e-02,  2.6407e+00,\n",
            "          3.4496e-01, -7.1536e-01,  2.5105e-01,  6.7496e-01,  1.9596e+00],\n",
            "        [-4.4051e-01, -2.0442e+00,  5.2581e-01, -9.7647e-01,  2.3082e+00,\n",
            "         -1.0127e+00,  1.0267e-01,  4.4057e-01, -5.8707e-01,  9.3186e-01],\n",
            "        [-2.2779e-01, -1.2220e+00,  1.4346e-01,  1.1377e-01, -5.2830e-01,\n",
            "          4.0101e-01,  2.0920e+00, -1.3172e+00, -1.5445e-01, -4.8130e-01],\n",
            "        [-5.1012e-02, -1.0511e+00, -2.6217e-01,  1.5884e+00, -8.6059e-01,\n",
            "          6.9325e-01,  3.6722e-02, -4.2329e-01, -2.4931e-01, -2.8512e-01],\n",
            "        [ 5.2747e-01, -1.4428e+00, -1.4239e+00,  5.7831e-02,  5.7279e-01,\n",
            "          1.2315e+00, -2.5383e-01, -3.5512e-01, -1.0021e-01,  4.7386e-01],\n",
            "        [ 2.9704e-01, -9.6869e-01, -4.1347e-01,  9.7865e-01, -1.0446e-02,\n",
            "          6.6920e-01, -1.8290e-01, -4.3079e-01,  2.4228e-01, -3.8940e-01],\n",
            "        [-9.7129e-02, -6.6292e-01,  1.1040e+00, -4.9680e-01,  5.2958e-01,\n",
            "         -1.0789e+00,  6.4402e-01, -7.8092e-01, -9.3652e-02, -7.5253e-01],\n",
            "        [ 1.3201e+00, -2.4157e+00, -4.9843e-01,  4.8594e-01, -7.6110e-01,\n",
            "          1.1134e+00,  2.7663e-01, -9.9277e-01,  1.0842e+00, -3.0106e-01],\n",
            "        [ 6.2491e-02, -2.8827e+00, -1.8841e-01, -6.8632e-01,  2.5876e+00,\n",
            "         -8.1541e-02,  2.2097e-01, -2.6511e-01, -1.8406e-01,  9.0180e-01],\n",
            "        [-8.9791e-01,  2.4004e+00, -2.3521e-02,  2.0676e-01, -8.7252e-01,\n",
            "         -2.8998e-01, -5.9763e-01, -1.2615e-01,  2.7359e-01, -2.0695e-01],\n",
            "        [-3.2756e-01, -1.9068e+00, -9.7252e-01, -1.0227e+00,  1.5438e+00,\n",
            "         -3.2576e-01, -2.5103e-01,  1.0663e+00, -3.4897e-01,  2.0392e+00],\n",
            "        [ 1.5972e-02,  1.3670e-01, -5.3537e-01, -2.9248e-01,  1.2551e-01,\n",
            "          3.4299e-01, -2.8916e-01,  3.6115e-01,  6.6000e-03, -1.8261e-01],\n",
            "        [-1.8197e-01, -1.8052e+00, -5.1358e-01,  6.5077e-01, -1.7591e-02,\n",
            "         -1.4190e-01, -1.4628e-01,  2.0505e+00, -5.2364e-01,  3.7870e-01],\n",
            "        [-3.0429e-02, -9.6031e-01,  9.6058e-01, -1.5561e+00,  4.1186e-02,\n",
            "          1.6556e-01,  5.6780e-01, -1.0473e+00,  1.1863e+00,  7.0672e-02],\n",
            "        [-7.2291e-01, -8.3273e-01, -2.2755e-02, -2.9587e-01,  6.3249e-01,\n",
            "          8.5562e-02,  4.9905e-03, -2.5606e-01,  3.3936e-01,  8.8226e-01],\n",
            "        [-9.7236e-01, -7.6498e-02,  1.1185e+00,  5.7806e-01, -2.4218e-01,\n",
            "         -4.4727e-02, -3.6206e-01, -7.2743e-01,  3.7169e-01, -8.6197e-02],\n",
            "        [-9.9101e-01, -9.2037e-01, -4.5531e-02, -7.2839e-01,  6.1525e-01,\n",
            "         -7.1527e-01, -4.1728e-01,  1.6600e+00,  1.7248e-02,  3.6182e-01],\n",
            "        [-1.3179e+00, -6.1589e-01, -5.6989e-01,  4.2475e-01,  6.0906e-01,\n",
            "          3.9954e-01,  2.9842e-02, -4.0949e-01,  6.3016e-01,  7.1125e-01],\n",
            "        [ 6.8443e-01, -3.7715e-01,  6.1190e-01, -2.9842e-01,  4.2200e-01,\n",
            "         -6.3285e-01,  6.5514e-01, -1.1413e-01, -3.8400e-01, -6.5379e-01],\n",
            "        [-5.8921e-01, -1.4393e+00,  5.3476e-01, -1.0749e+00,  1.9676e+00,\n",
            "         -8.9989e-01, -3.4289e-01,  3.7683e-01,  9.5922e-02,  7.1267e-01],\n",
            "        [-1.5354e+00, -3.5187e-01, -5.6949e-01,  2.5547e+00, -6.3439e-01,\n",
            "          8.9714e-01, -1.0430e+00, -1.0007e+00,  8.9467e-01, -2.7372e-01],\n",
            "        [ 2.6463e+00, -1.2830e+00,  5.7536e-01, -5.7083e-01, -1.3064e+00,\n",
            "          4.9746e-01,  2.9781e-02, -3.4442e-01, -2.3361e-01, -6.3165e-01],\n",
            "        [ 3.3898e-01, -1.2821e+00, -7.9422e-01, -2.3339e-02, -1.1529e-01,\n",
            "         -4.3996e-01, -8.2607e-01,  2.8026e+00, -3.9425e-01,  4.7255e-01],\n",
            "        [ 4.4059e+00, -2.7535e+00,  7.5409e-01,  3.2182e-01, -8.6395e-01,\n",
            "          1.0201e+00, -1.1916e-01, -1.8368e+00,  3.4855e-01, -1.6968e+00],\n",
            "        [ 1.3885e+00, -1.1144e+00,  1.6021e+00,  1.1943e+00, -1.1371e+00,\n",
            "          1.5762e-01,  4.0186e-01, -9.1216e-01,  1.5929e-01, -2.1037e+00],\n",
            "        [-1.4796e+00,  6.8276e-01,  1.6546e-01, -2.3226e-01, -9.9596e-01,\n",
            "         -6.0140e-01, -9.1711e-01,  7.6401e-01,  1.2803e+00,  4.2915e-01],\n",
            "        [-1.2904e+00,  2.2314e+00, -5.0939e-01, -7.2642e-02, -8.2227e-01,\n",
            "         -1.0828e-01, -1.4079e-01, -9.6544e-02,  4.5238e-01, -1.9965e-01],\n",
            "        [-1.7175e+00,  3.6942e-01, -4.5062e-01, -4.4164e-01,  8.7026e-01,\n",
            "         -5.3531e-01, -8.0338e-01,  1.6696e+00, -2.7226e-03,  6.1750e-01],\n",
            "        [-3.4532e-01,  1.9069e-01, -4.4524e-01,  2.2986e+00, -1.1115e+00,\n",
            "          1.0428e+00, -5.6244e-01, -1.2277e+00,  5.8174e-01, -8.4226e-01],\n",
            "        [-8.1355e-01, -3.6013e-01,  7.0845e-01, -7.1406e-01, -1.5011e-01,\n",
            "         -6.5289e-01, -4.3224e-02,  1.6981e+00, -3.6180e-01,  5.5064e-01],\n",
            "        [-1.8076e+00,  9.6481e-01, -8.0931e-01,  2.4191e-02, -2.0128e-01,\n",
            "          2.8604e-02, -5.9507e-01,  1.5908e-01,  8.2933e-01,  5.5208e-01],\n",
            "        [-6.7201e-01, -5.8111e-01, -6.9594e-01, -1.1185e+00, -7.4198e-02,\n",
            "         -4.8338e-01, -1.4311e+00,  3.2616e+00,  2.5733e-01,  8.0840e-01],\n",
            "        [-4.7872e-01, -1.7142e+00, -9.6722e-01, -3.1702e-01,  7.7988e-01,\n",
            "          3.6662e-01, -3.2294e-01,  1.4802e+00, -5.6034e-01,  1.6624e+00],\n",
            "        [ 1.6003e-01, -2.0356e+00,  5.2765e-01, -5.2980e-01,  1.0883e-01,\n",
            "          1.7721e-01,  2.3781e+00, -5.5705e-01, -3.3607e-01,  4.1925e-02],\n",
            "        [-6.9092e-01, -1.1841e+00,  4.0209e+00, -1.6155e-01, -3.0590e-01,\n",
            "         -1.0606e+00,  8.4878e-01, -1.0540e+00,  4.5980e-01, -1.4277e+00],\n",
            "        [-5.4688e-01, -1.6254e+00, -6.6793e-01, -3.2951e-01,  6.6296e-01,\n",
            "         -1.2668e-01, -9.8177e-01,  2.1584e+00, -2.1866e-01,  1.4912e+00],\n",
            "        [-9.0167e-01, -9.8321e-02, -3.2717e-01, -4.9094e-01,  6.2512e-01,\n",
            "          3.8616e-01, -6.2863e-01, -6.9498e-01,  9.5818e-01,  6.8786e-01],\n",
            "        [-9.3103e-01, -2.5216e+00, -9.2466e-01,  1.5118e-03,  2.8220e+00,\n",
            "          1.5077e-02, -3.5007e-01, -3.5820e-01,  2.7636e-01,  1.3550e+00],\n",
            "        [-1.7981e+00,  6.1417e-01, -1.9466e-01, -7.9403e-01, -1.8880e-02,\n",
            "         -8.0831e-01, -1.1675e+00,  3.0494e+00,  1.8758e-01,  8.9256e-01],\n",
            "        [-7.9668e-03, -1.6842e+00, -1.1418e+00,  1.8055e+00, -4.5093e-01,\n",
            "          1.0232e+00,  5.8312e-01, -4.2853e-01,  7.9962e-02, -8.1180e-02],\n",
            "        [-7.3622e-02, -2.1725e+00,  7.8471e-01, -1.2323e+00,  1.0638e+00,\n",
            "         -5.7115e-01,  2.7022e+00, -9.0849e-02, -6.6805e-01,  3.1700e-01],\n",
            "        [-1.6093e+00,  3.0599e+00,  3.5089e-01,  1.3673e-02, -5.8518e-01,\n",
            "         -3.9025e-01, -2.5752e-01, -2.8974e-01,  4.6251e-01, -5.7385e-01],\n",
            "        [ 4.0157e-01, -6.7478e-01, -1.7568e-01,  2.8012e+00, -1.2047e+00,\n",
            "          6.7996e-01, -1.2858e+00, -5.7950e-01,  7.5460e-01, -7.2799e-01],\n",
            "        [-8.8018e-01, -8.5300e-01,  2.8411e-01, -6.4240e-01,  4.5206e-01,\n",
            "         -3.1829e-01,  2.7277e+00, -1.1819e+00,  6.9463e-02,  1.6659e-01],\n",
            "        [-9.5538e-01, -7.2354e-02,  4.1384e-02, -6.7228e-01,  4.3625e-01,\n",
            "         -2.3223e-01, -1.5221e-01, -2.4973e-01,  5.5565e-01,  3.9045e-01],\n",
            "        [-8.2391e-01, -5.6880e-01, -7.9159e-01,  2.4168e+00, -1.5581e+00,\n",
            "          1.0732e+00, -1.2384e+00,  4.2025e-01,  6.5662e-01, -1.4719e-01],\n",
            "        [-1.9401e+00,  1.7388e+00, -9.7568e-02,  1.3725e-01, -4.6187e-01,\n",
            "          3.3853e-02,  3.0020e-01, -3.3865e-01,  7.1834e-01, -2.4664e-01],\n",
            "        [-6.5489e-01, -3.0819e-01, -2.1847e-01, -1.3987e+00,  2.1783e+00,\n",
            "         -5.8718e-01,  3.3705e-01, -9.4047e-02, -2.1739e-01,  1.3558e+00],\n",
            "        [-9.0113e-01,  5.2723e-01, -3.6586e-01,  3.1965e-01, -1.4158e-01,\n",
            "          2.0621e-01, -2.6202e-01, -1.4693e-02,  3.4228e-01,  1.3597e-01],\n",
            "        [-1.9646e+00,  1.4782e+00, -6.6321e-01, -6.7602e-02, -2.5451e-01,\n",
            "         -3.5910e-01, -2.0881e-01,  9.1416e-01,  1.5900e-03,  4.8461e-01],\n",
            "        [ 1.0257e+00, -1.2750e+00,  7.8082e-01, -7.9823e-01, -2.4645e-01,\n",
            "          5.3688e-01,  1.8486e+00, -1.2049e+00, -8.3052e-02, -7.9917e-01],\n",
            "        [-1.1324e+00, -1.7585e+00,  1.0185e-01, -8.8069e-01,  1.5587e+00,\n",
            "         -1.0608e+00, -5.5262e-01,  8.6302e-01, -1.1806e-01,  2.1916e+00]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyAjSJqlVHcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ea8784a-0475-4296-a602-523e8bd257d5"
      },
      "source": [
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "    iter_test += 1\n",
        "    images = images.view(-1, 28*28).requires_grad_()\n",
        "    outputs = model(images)\n",
        "    if iter_test == 1:\n",
        "        print('OUTPUTS')\n",
        "        print(outputs.size())\n",
        "    _, predicted = torch.max(outputs.data, 1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OUTPUTS\n",
            "torch.Size([100, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWNqQYf4VHcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e295e943-8a68-4dbf-8cba-e3e3b3f47b54"
      },
      "source": [
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "    iter_test += 1\n",
        "    images = images.view(-1, 28*28).requires_grad_()\n",
        "    outputs = model(images)\n",
        "    if iter_test == 1:\n",
        "        print('OUTPUTS')\n",
        "        print(outputs[0, :])\n",
        "    _, predicted = torch.max(outputs.data, 1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OUTPUTS\n",
            "tensor([-0.5311, -1.0376, -0.4672, -0.2383,  0.0391, -0.4347, -1.1110,  3.0440,\n",
            "        -0.2243,  0.8348], grad_fn=<SliceBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhXrpXJ-VHc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7d0e27cf-d4b7-4eff-c222-d597da39bb98"
      },
      "source": [
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "    iter_test += 1\n",
        "    images = images.view(-1, 28*28).requires_grad_()\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    if iter_test == 1:\n",
        "        print('PREDICTION')\n",
        "        print(predicted.size())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION\n",
            "torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO7CJXFGVHc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e977df33-cd46-4b9c-9c1d-cabf6427effa"
      },
      "source": [
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "    iter_test += 1\n",
        "    images = images.view(-1, 28*28).requires_grad_()\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    if iter_test == 1:\n",
        "        print('PREDICTION')\n",
        "        print(predicted[0])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION\n",
            "tensor(7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0cO2g0aVHdE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "df793542-7c8c-4982-abaa-5b0e345cbb83"
      },
      "source": [
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "    iter_test += 1\n",
        "    images = images.view(-1, 28*28).requires_grad_()\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    if iter_test == 1:\n",
        "        print('PREDICTION')\n",
        "        print(predicted[0])\n",
        "        \n",
        "        print('LABEL SIZE')\n",
        "        print(labels.size())\n",
        "        \n",
        "        print('LABEL FOR IMAGE 0')\n",
        "        print(labels[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION\n",
            "tensor(7)\n",
            "LABEL SIZE\n",
            "torch.Size([100])\n",
            "LABEL FOR IMAGE 0\n",
            "tensor(7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm0WAGi2VHdL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e8dcbff6-6b2b-4660-b3f0-574853661432"
      },
      "source": [
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "    iter_test += 1\n",
        "    images = images.view(-1, 28*28).requires_grad_()\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    \n",
        "    if iter_test == 1:\n",
        "        print('PREDICTION')\n",
        "        print(predicted[1])\n",
        "        \n",
        "        print('LABEL SIZE')\n",
        "        print(labels.size())\n",
        "        \n",
        "        print('LABEL FOR IMAGE 1')\n",
        "        print(labels[1])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION\n",
            "tensor(2)\n",
            "LABEL SIZE\n",
            "torch.Size([100])\n",
            "LABEL FOR IMAGE 1\n",
            "tensor(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0jLqYCKVHdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a991e1d6-e137-4b49-99ef-082c4a18dbe2"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "iter_test = 0\n",
        "for images, labels in test_loader:\n",
        "    iter_test += 1\n",
        "    images = images.view(-1, 28*28).requires_grad_()\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    \n",
        "    # Total number of labels\n",
        "    total += labels.size(0)\n",
        "\n",
        "    # Total correct predictions\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "accuracy = 100 * (correct.item() / total)\n",
        "\n",
        "print(accuracy)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA4t2dvpVHdZ",
        "colab_type": "text"
      },
      "source": [
        "#### Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RC8eLZAVHda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_model = False\n",
        "if save_model is True:\n",
        "    # Saves only parameters\n",
        "    torch.save(model.state_dict(), 'awesome_model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4Gq0_inVHdd",
        "colab_type": "text"
      },
      "source": [
        "## 3. Building a Logistic Regression Model with PyTorch (GPU)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxcDJ8B0VHde",
        "colab_type": "text"
      },
      "source": [
        "**CPU Version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvQTUmpOVHdi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0bddfefd-72e9-43b2-e7cd-40ef68021b2a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 28*28\n",
        "output_dim = 10\n",
        "\n",
        "model = LogisticRegressionModel(input_dim, output_dim)\n",
        "\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Load images as Variable\n",
        "        images = images.view(-1, 28*28).requires_grad_()\n",
        "        labels = labels\n",
        "        \n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass to get output/logits\n",
        "        # 100 x 10\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "        \n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        iter += 1\n",
        "        \n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                # Load images to a Torch Variable\n",
        "                images = images.view(-1, 28*28).requires_grad_()\n",
        "                \n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "                \n",
        "                # Get predictions from the maximum value\n",
        "                # 100 x 1\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "                \n",
        "                # Total correct predictions\n",
        "                correct += (predicted == labels).sum()\n",
        "            \n",
        "            accuracy = 100 * correct.item() / total\n",
        "            \n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 1.8585511445999146. Accuracy: 67.13\n",
            "Iteration: 1000. Loss: 1.5915520191192627. Accuracy: 76.49\n",
            "Iteration: 1500. Loss: 1.3948060274124146. Accuracy: 79.9\n",
            "Iteration: 2000. Loss: 1.2040984630584717. Accuracy: 81.25\n",
            "Iteration: 2500. Loss: 1.131636619567871. Accuracy: 82.36\n",
            "Iteration: 3000. Loss: 0.9151694774627686. Accuracy: 83.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPK_-vMuVHdp",
        "colab_type": "text"
      },
      "source": [
        "GPU: 2 things must be on GPU\n",
        "- `model`\n",
        "- `variables`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Sp9Ngv5VHdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cb33cc5c-4e04-4743-8d19-bdd9585d6b47"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "'''\n",
        "STEP 1: LOADING DATASET\n",
        "'''\n",
        "\n",
        "train_dataset = dsets.MNIST(root='./data', \n",
        "                            train=True, \n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "'''\n",
        "STEP 2: MAKING DATASET ITERABLE\n",
        "'''\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 28*28\n",
        "output_dim = 10\n",
        "\n",
        "model = LogisticRegressionModel(input_dim, output_dim)\n",
        "\n",
        "#######################\n",
        "#  USE GPU FOR MODEL  #\n",
        "#######################\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        \n",
        "        #######################\n",
        "        #  USE GPU FOR MODEL  #\n",
        "        #######################\n",
        "        images = images.view(-1, 28*28).requires_grad_().to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "        \n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "        iter += 1\n",
        "        \n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                #######################\n",
        "                #  USE GPU FOR MODEL  #\n",
        "                #######################\n",
        "                images = images.view(-1, 28*28).to(device)\n",
        "                \n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "                \n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "                \n",
        "                #######################\n",
        "                #  USE GPU FOR MODEL  #\n",
        "                #######################\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "            \n",
        "            accuracy = 100 * correct.item() / total\n",
        "            \n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 500. Loss: 1.8681875467300415. Accuracy: 69.52\n",
            "Iteration: 1000. Loss: 1.5914909839630127. Accuracy: 76.78\n",
            "Iteration: 1500. Loss: 1.4236671924591064. Accuracy: 79.06\n",
            "Iteration: 2000. Loss: 1.0975348949432373. Accuracy: 80.97\n",
            "Iteration: 2500. Loss: 1.0723942518234253. Accuracy: 82.21\n",
            "Iteration: 3000. Loss: 0.9762925505638123. Accuracy: 83.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxoVuiIlVHds",
        "colab_type": "text"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ5zofngVHds",
        "colab_type": "text"
      },
      "source": [
        "- **Logistic regression** basics\n",
        "- **Problems** of **linear regression**\n",
        "- **In-depth** Logistic Regression\n",
        "    1. Get logits\n",
        "    2. Get softmax\n",
        "    3. Get cross-entropy loss\n",
        "- **Aim**: reduce cross-entropy loss\n",
        "- Built a **logistic regression model** in **CPU and GPU**\n",
        "    - Step 1: Load Dataset\n",
        "    - Step 2: Make Dataset Iterable\n",
        "    - Step 3: Create Model Class\n",
        "    - Step 4: Instantiate Model Class\n",
        "    - Step 5: Instantiate Loss Class\n",
        "    - Step 6: Instantiate Optimizer Class\n",
        "    - Step 7: Train Model\n",
        "- Important things to be on **GPU**\n",
        "    - `model`\n",
        "    - `tensors with gradients`"
      ]
    }
  ]
}